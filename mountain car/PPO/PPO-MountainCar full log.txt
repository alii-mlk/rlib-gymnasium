(avis) ali@Mac PPO % python ppo.py 
/Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
2025-07-08 21:54:15,085	INFO worker.py:1528 -- Started a local Ray instance.

[INFO] Starting PPO training on RandomizedMountainCar-v1 with RANDOMIZED INITIAL STATES...

WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1752004455.773643 2881948 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers
2025-07-08 21:54:15,782	INFO ppo.py:379 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting simple_optimizer=True if this doesn't work for you.
2025-07-08 21:54:15,783	INFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
2025-07-08 21:54:18,982	WARNING util.py:66 -- Install gputil for GPU system monitoring.
Iteration 1: episode_reward_mean = -174.24
Iteration 2: episode_reward_mean = -165.79
Iteration 3: episode_reward_mean = -162.39
Iteration 4: episode_reward_mean = -156.87
Iteration 5: episode_reward_mean = -150.79
Iteration 6: episode_reward_mean = -149.17
Iteration 7: episode_reward_mean = -147.58
Iteration 8: episode_reward_mean = -152.80
Iteration 9: episode_reward_mean = -160.85
Iteration 10: episode_reward_mean = -163.74
Iteration 11: episode_reward_mean = -163.27
Iteration 12: episode_reward_mean = -151.96
Iteration 13: episode_reward_mean = -153.54
Iteration 14: episode_reward_mean = -155.49
Iteration 15: episode_reward_mean = -153.58
Iteration 16: episode_reward_mean = -164.61
Iteration 17: episode_reward_mean = -162.44
Iteration 18: episode_reward_mean = -164.26
Iteration 19: episode_reward_mean = -160.24
Iteration 20: episode_reward_mean = -156.40
Iteration 21: episode_reward_mean = -154.49
Iteration 22: episode_reward_mean = -148.91
Iteration 23: episode_reward_mean = -149.22
Iteration 24: episode_reward_mean = -151.13
Iteration 25: episode_reward_mean = -156.65
Iteration 26: episode_reward_mean = -162.10
Iteration 27: episode_reward_mean = -173.51
Iteration 28: episode_reward_mean = -177.04
Iteration 29: episode_reward_mean = -173.48
Iteration 30: episode_reward_mean = -175.75
Iteration 31: episode_reward_mean = -164.08
Iteration 32: episode_reward_mean = -158.72
Iteration 33: episode_reward_mean = -168.25
Iteration 34: episode_reward_mean = -166.10
Iteration 35: episode_reward_mean = -166.12
Iteration 36: episode_reward_mean = -169.98
Iteration 37: episode_reward_mean = -163.71
Iteration 38: episode_reward_mean = -165.70
Iteration 39: episode_reward_mean = -173.35
Iteration 40: episode_reward_mean = -172.19
Iteration 41: episode_reward_mean = -170.35
Iteration 42: episode_reward_mean = -162.57
Iteration 43: episode_reward_mean = -160.33
Iteration 44: episode_reward_mean = -158.16
Iteration 45: episode_reward_mean = -153.13
Iteration 46: episode_reward_mean = -157.13
Iteration 47: episode_reward_mean = -148.65
Iteration 48: episode_reward_mean = -154.05
Iteration 49: episode_reward_mean = -155.98
Iteration 50: episode_reward_mean = -157.93
Iteration 51: episode_reward_mean = -166.66
Iteration 52: episode_reward_mean = -156.76
Iteration 53: episode_reward_mean = -160.25
Iteration 54: episode_reward_mean = -154.38
Iteration 55: episode_reward_mean = -154.22
Iteration 56: episode_reward_mean = -160.30
Iteration 57: episode_reward_mean = -163.95
Iteration 58: episode_reward_mean = -164.32
Iteration 59: episode_reward_mean = -172.16
Iteration 60: episode_reward_mean = -173.98
Iteration 61: episode_reward_mean = -170.18
Iteration 62: episode_reward_mean = -163.10
Iteration 63: episode_reward_mean = -158.02
Iteration 64: episode_reward_mean = -152.33
Iteration 65: episode_reward_mean = -156.58
Iteration 66: episode_reward_mean = -159.58
Iteration 67: episode_reward_mean = -158.82
Iteration 68: episode_reward_mean = -162.79
Iteration 69: episode_reward_mean = -164.33
Iteration 70: episode_reward_mean = -168.40
Iteration 71: episode_reward_mean = -172.85
Iteration 72: episode_reward_mean = -171.14
Iteration 73: episode_reward_mean = -162.10
Iteration 74: episode_reward_mean = -151.14
Iteration 75: episode_reward_mean = -156.51
Iteration 76: episode_reward_mean = -145.39
Iteration 77: episode_reward_mean = -145.12
Iteration 78: episode_reward_mean = -144.90
Iteration 79: episode_reward_mean = -142.62
Iteration 80: episode_reward_mean = -141.59
Iteration 81: episode_reward_mean = -149.24
Iteration 82: episode_reward_mean = -146.39
Iteration 83: episode_reward_mean = -144.25
Iteration 84: episode_reward_mean = -151.61
Iteration 85: episode_reward_mean = -147.50
Iteration 86: episode_reward_mean = -151.11
Iteration 87: episode_reward_mean = -155.35
Iteration 88: episode_reward_mean = -153.91
Iteration 89: episode_reward_mean = -159.56
Iteration 90: episode_reward_mean = -163.18
Iteration 91: episode_reward_mean = -155.70
Iteration 92: episode_reward_mean = -155.59
Iteration 93: episode_reward_mean = -154.04
Iteration 94: episode_reward_mean = -150.78
Iteration 95: episode_reward_mean = -157.84
Iteration 96: episode_reward_mean = -153.46
Iteration 97: episode_reward_mean = -144.20
Iteration 98: episode_reward_mean = -143.50
Iteration 99: episode_reward_mean = -144.01
Iteration 100: episode_reward_mean = -146.41
Iteration 101: episode_reward_mean = -146.96
Iteration 102: episode_reward_mean = -150.31
Iteration 103: episode_reward_mean = -148.96
Iteration 104: episode_reward_mean = -152.05
Iteration 105: episode_reward_mean = -151.80
Iteration 106: episode_reward_mean = -157.92
Iteration 107: episode_reward_mean = -153.81
Iteration 108: episode_reward_mean = -145.44
Iteration 109: episode_reward_mean = -146.60
Iteration 110: episode_reward_mean = -146.91
Iteration 111: episode_reward_mean = -152.60
Iteration 112: episode_reward_mean = -162.93
Iteration 113: episode_reward_mean = -165.39
Iteration 114: episode_reward_mean = -165.43
Iteration 115: episode_reward_mean = -160.73
Iteration 116: episode_reward_mean = -145.39
Iteration 117: episode_reward_mean = -149.47
Iteration 118: episode_reward_mean = -145.44
Iteration 119: episode_reward_mean = -151.44
Iteration 120: episode_reward_mean = -153.18
Iteration 121: episode_reward_mean = -143.58
Iteration 122: episode_reward_mean = -157.05
Iteration 123: episode_reward_mean = -159.02
Iteration 124: episode_reward_mean = -160.88
Iteration 125: episode_reward_mean = -165.17
Iteration 126: episode_reward_mean = -161.00
Iteration 127: episode_reward_mean = -153.84
Iteration 128: episode_reward_mean = -154.26
Iteration 129: episode_reward_mean = -151.85
Iteration 130: episode_reward_mean = -150.33
Iteration 131: episode_reward_mean = -151.70
Iteration 132: episode_reward_mean = -145.68
Iteration 133: episode_reward_mean = -141.72
Iteration 134: episode_reward_mean = -144.74
Iteration 135: episode_reward_mean = -146.59
Iteration 136: episode_reward_mean = -145.19
Iteration 137: episode_reward_mean = -150.82
Iteration 138: episode_reward_mean = -148.94
Iteration 139: episode_reward_mean = -146.50
Iteration 140: episode_reward_mean = -152.76
Iteration 141: episode_reward_mean = -148.46
Iteration 142: episode_reward_mean = -151.70
Iteration 143: episode_reward_mean = -150.75
Iteration 144: episode_reward_mean = -144.29
Iteration 145: episode_reward_mean = -145.30
Iteration 146: episode_reward_mean = -146.23
Iteration 147: episode_reward_mean = -150.26
Iteration 148: episode_reward_mean = -148.54
Iteration 149: episode_reward_mean = -147.50
Iteration 150: episode_reward_mean = -151.48
Iteration 151: episode_reward_mean = -144.09
Iteration 152: episode_reward_mean = -145.18
Iteration 153: episode_reward_mean = -143.56
Iteration 154: episode_reward_mean = -140.94
Iteration 155: episode_reward_mean = -147.03
Iteration 156: episode_reward_mean = -151.66
Iteration 157: episode_reward_mean = -141.54
Iteration 158: episode_reward_mean = -141.79
Iteration 159: episode_reward_mean = -142.42
Iteration 160: episode_reward_mean = -140.22
Iteration 161: episode_reward_mean = -145.04
Iteration 162: episode_reward_mean = -146.99
Iteration 163: episode_reward_mean = -154.58
Iteration 164: episode_reward_mean = -150.65
Iteration 165: episode_reward_mean = -155.82
Iteration 166: episode_reward_mean = -157.45
Iteration 167: episode_reward_mean = -155.75
Iteration 168: episode_reward_mean = -148.01
Iteration 169: episode_reward_mean = -143.93
Iteration 170: episode_reward_mean = -143.18
Iteration 171: episode_reward_mean = -137.93
Iteration 172: episode_reward_mean = -135.04
Iteration 173: episode_reward_mean = -133.47
Iteration 174: episode_reward_mean = -141.41
Iteration 175: episode_reward_mean = -149.25
Iteration 176: episode_reward_mean = -144.09
Iteration 177: episode_reward_mean = -147.06
Iteration 178: episode_reward_mean = -140.61
Iteration 179: episode_reward_mean = -144.80
Iteration 180: episode_reward_mean = -149.89
Iteration 181: episode_reward_mean = -153.70
Iteration 182: episode_reward_mean = -151.78
Iteration 183: episode_reward_mean = -144.77
Iteration 184: episode_reward_mean = -151.81
Iteration 185: episode_reward_mean = -151.98
Iteration 186: episode_reward_mean = -155.22
Iteration 187: episode_reward_mean = -155.14
Iteration 188: episode_reward_mean = -156.49
Iteration 189: episode_reward_mean = -161.93
Iteration 190: episode_reward_mean = -154.84
Iteration 191: episode_reward_mean = -148.58
Iteration 192: episode_reward_mean = -137.20
Iteration 193: episode_reward_mean = -146.27
Iteration 194: episode_reward_mean = -149.96
Iteration 195: episode_reward_mean = -150.01
Iteration 196: episode_reward_mean = -153.86
Iteration 197: episode_reward_mean = -150.00
Iteration 198: episode_reward_mean = -152.28
Iteration 199: episode_reward_mean = -152.03
Iteration 200: episode_reward_mean = -147.82
Iteration 201: episode_reward_mean = -146.90
Iteration 202: episode_reward_mean = -143.52
Iteration 203: episode_reward_mean = -148.71
Iteration 204: episode_reward_mean = -147.61
Iteration 205: episode_reward_mean = -144.29
Iteration 206: episode_reward_mean = -144.71
Iteration 207: episode_reward_mean = -139.50
Iteration 208: episode_reward_mean = -139.14
Iteration 209: episode_reward_mean = -136.50
Iteration 210: episode_reward_mean = -139.43
Iteration 211: episode_reward_mean = -141.80
Iteration 212: episode_reward_mean = -138.81
Iteration 213: episode_reward_mean = -142.47
Iteration 214: episode_reward_mean = -142.50
Iteration 215: episode_reward_mean = -149.76
Iteration 216: episode_reward_mean = -157.26
Iteration 217: episode_reward_mean = -156.80
Iteration 218: episode_reward_mean = -154.48
Iteration 219: episode_reward_mean = -149.03
Iteration 220: episode_reward_mean = -147.18
Iteration 221: episode_reward_mean = -140.17
Iteration 222: episode_reward_mean = -140.48
Iteration 223: episode_reward_mean = -146.27
Iteration 224: episode_reward_mean = -142.36
Iteration 225: episode_reward_mean = -150.11
Iteration 226: episode_reward_mean = -150.25
Iteration 227: episode_reward_mean = -149.04
Iteration 228: episode_reward_mean = -152.47
Iteration 229: episode_reward_mean = -152.92
Iteration 230: episode_reward_mean = -151.45
Iteration 231: episode_reward_mean = -145.69
Iteration 232: episode_reward_mean = -138.32
Iteration 233: episode_reward_mean = -139.29
Iteration 234: episode_reward_mean = -138.15
Iteration 235: episode_reward_mean = -146.59
Iteration 236: episode_reward_mean = -147.36
Iteration 237: episode_reward_mean = -142.25
Iteration 238: episode_reward_mean = -135.32
Iteration 239: episode_reward_mean = -141.47
Iteration 240: episode_reward_mean = -129.67
Iteration 241: episode_reward_mean = -129.14
Iteration 242: episode_reward_mean = -136.32
Iteration 243: episode_reward_mean = -138.64
Iteration 244: episode_reward_mean = -151.89
Iteration 245: episode_reward_mean = -138.44
Iteration 246: episode_reward_mean = -140.99
Iteration 247: episode_reward_mean = -149.54
Iteration 248: episode_reward_mean = -152.07
Iteration 249: episode_reward_mean = -150.38
Iteration 250: episode_reward_mean = -159.38
Iteration 251: episode_reward_mean = -152.54
Iteration 252: episode_reward_mean = -147.18
Iteration 253: episode_reward_mean = -146.92
Iteration 254: episode_reward_mean = -141.23
Iteration 255: episode_reward_mean = -138.69
Iteration 256: episode_reward_mean = -141.23
Iteration 257: episode_reward_mean = -140.89
Iteration 258: episode_reward_mean = -150.28
Iteration 259: episode_reward_mean = -153.76
Iteration 260: episode_reward_mean = -145.58
Iteration 261: episode_reward_mean = -144.53
Iteration 262: episode_reward_mean = -137.23
Iteration 263: episode_reward_mean = -141.10
Iteration 264: episode_reward_mean = -142.83
Iteration 265: episode_reward_mean = -153.49
Iteration 266: episode_reward_mean = -157.42
Iteration 267: episode_reward_mean = -153.35
Iteration 268: episode_reward_mean = -150.46
Iteration 269: episode_reward_mean = -152.17
Iteration 270: episode_reward_mean = -154.06
Iteration 271: episode_reward_mean = -156.33
Iteration 272: episode_reward_mean = -159.31
Iteration 273: episode_reward_mean = -157.03
Iteration 274: episode_reward_mean = -152.97
Iteration 275: episode_reward_mean = -153.08
Iteration 276: episode_reward_mean = -147.59
Iteration 277: episode_reward_mean = -141.44
Iteration 278: episode_reward_mean = -141.26
Iteration 279: episode_reward_mean = -141.54
Iteration 280: episode_reward_mean = -138.76
Iteration 281: episode_reward_mean = -143.96
Iteration 282: episode_reward_mean = -144.07
Iteration 283: episode_reward_mean = -144.35
Iteration 284: episode_reward_mean = -146.80
Iteration 285: episode_reward_mean = -146.74
Iteration 286: episode_reward_mean = -150.42
Iteration 287: episode_reward_mean = -155.66
Iteration 288: episode_reward_mean = -161.93
Iteration 289: episode_reward_mean = -158.01
Iteration 290: episode_reward_mean = -142.51
Iteration 291: episode_reward_mean = -127.36
Iteration 292: episode_reward_mean = -129.46
Iteration 293: episode_reward_mean = -135.44
Iteration 294: episode_reward_mean = -149.81
Iteration 295: episode_reward_mean = -153.57
Iteration 296: episode_reward_mean = -158.72
Iteration 297: episode_reward_mean = -151.31
Iteration 298: episode_reward_mean = -142.57
Iteration 299: episode_reward_mean = -133.78
Iteration 300: episode_reward_mean = -141.18

[INFO] Checkpoint saved at: /Users/ali/ray_results/PPO_RandomizedMountainCar-v1_2025-07-08_21-54-15lq6ssg6n/checkpoint_000300

[INFO] Training Complete
Avg Training CPU Usage: 36.39%
Peak Memory Usage: 422.27 MB
Final Memory Change: 29.17 MB
Training Time: 924.24 seconds

Running trained PPO policy on RandomizedMountainCar-v1 and logging state evolution...

(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
2025-07-08 22:09:43,701	WARNING util.py:66 -- Install gputil for GPU system monitoring.
2025-07-08 22:09:43,706	INFO trainable.py:766 -- Restored on 127.0.0.1 from checkpoint: /Users/ali/ray_results/PPO_RandomizedMountainCar-v1_2025-07-08_21-54-15lq6ssg6n/checkpoint_000300
2025-07-08 22:09:43,706	INFO trainable.py:775 -- Current state after restoring: {'_iteration': 300, '_timesteps_total': None, '_time_total': 918.5837533473969, '_episodes_total': 7944}
Inference log saved to mountaincar_inference_PPO_log.csv

State plot saved to PPO-MountainCar-v1.png