(avis) ali@Mac DQN % python dqn.py 
/Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import packaging
2025-07-07 13:20:24,544	INFO worker.py:1528 -- Started a local Ray instance.
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging
(raylet) /Users/ali/miniforge3/envs/avis/lib/python3.10/site-packages/ray/air/_internal/remote_storage.py:4: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
(raylet)   from pkg_resources import packaging

Starting DQN training on RandomizedCartPole-v1 with RANDOMIZED INITIAL STATES...

WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1751887225.198468 1926777 fork_posix.cc:71] Other threads are currently calling into gRPC, skipping fork() handlers
2025-07-07 13:20:25,206	INFO simple_q.py:307 -- In multi-agent mode, policies will be optimized sequentially by the multi-GPU optimizer. Consider setting `simple_optimizer=True` if this doesn't work for you.
2025-07-07 13:20:25,207	INFO algorithm.py:457 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.
2025-07-07 13:20:26,030	WARNING util.py:66 -- Install gputil for GPU system monitoring.
2025-07-07 13:20:26,046	WARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.
Iteration 1: episode_reward_mean = 19.10
2025-07-07 13:20:26,610	WARNING deprecation.py:47 -- DeprecationWarning: `concat_samples` has been deprecated. Use `concat_samples() from rllib.policy.sample_batch` instead. This will raise an error in the future!
Iteration 2: episode_reward_mean = 17.69
Iteration 3: episode_reward_mean = 18.24
Iteration 4: episode_reward_mean = 22.53
Iteration 5: episode_reward_mean = 28.47
Iteration 6: episode_reward_mean = 34.77
Iteration 7: episode_reward_mean = 43.31
Iteration 8: episode_reward_mean = 53.86
Iteration 9: episode_reward_mean = 62.63
Iteration 10: episode_reward_mean = 69.48
Iteration 11: episode_reward_mean = 76.37
Iteration 12: episode_reward_mean = 87.10
Iteration 13: episode_reward_mean = 99.01
Iteration 14: episode_reward_mean = 106.19
Iteration 15: episode_reward_mean = 118.30
Iteration 16: episode_reward_mean = 125.91
Iteration 17: episode_reward_mean = 134.47
Iteration 18: episode_reward_mean = 141.33
Iteration 19: episode_reward_mean = 147.01
Iteration 20: episode_reward_mean = 154.01
Iteration 21: episode_reward_mean = 161.13
Iteration 22: episode_reward_mean = 168.18
Iteration 23: episode_reward_mean = 174.31
Iteration 24: episode_reward_mean = 175.40
Iteration 25: episode_reward_mean = 164.57
Iteration 26: episode_reward_mean = 146.76
Iteration 27: episode_reward_mean = 133.00
Iteration 28: episode_reward_mean = 127.76
Iteration 29: episode_reward_mean = 126.12
Iteration 30: episode_reward_mean = 128.62
Iteration 31: episode_reward_mean = 129.60
Iteration 32: episode_reward_mean = 128.39
Iteration 33: episode_reward_mean = 121.20
Iteration 34: episode_reward_mean = 119.85
Iteration 35: episode_reward_mean = 117.50
Iteration 36: episode_reward_mean = 117.70
Iteration 37: episode_reward_mean = 120.15
Iteration 38: episode_reward_mean = 122.78
Iteration 39: episode_reward_mean = 124.72
Iteration 40: episode_reward_mean = 126.87
Iteration 41: episode_reward_mean = 130.42
Iteration 42: episode_reward_mean = 133.48
Iteration 43: episode_reward_mean = 135.80
Iteration 44: episode_reward_mean = 137.19
Iteration 45: episode_reward_mean = 137.30
Iteration 46: episode_reward_mean = 140.41
Iteration 47: episode_reward_mean = 143.35
Iteration 48: episode_reward_mean = 149.22
Iteration 49: episode_reward_mean = 152.49
Iteration 50: episode_reward_mean = 157.86
Iteration 51: episode_reward_mean = 163.87
Iteration 52: episode_reward_mean = 169.24
Iteration 53: episode_reward_mean = 171.45
Iteration 54: episode_reward_mean = 179.54
Iteration 55: episode_reward_mean = 187.30
Iteration 56: episode_reward_mean = 194.58
Iteration 57: episode_reward_mean = 199.05
Iteration 58: episode_reward_mean = 203.66
Iteration 59: episode_reward_mean = 209.09
Iteration 60: episode_reward_mean = 216.37
Iteration 61: episode_reward_mean = 223.59
Iteration 62: episode_reward_mean = 230.19
Iteration 63: episode_reward_mean = 236.76
Iteration 64: episode_reward_mean = 243.21
Iteration 65: episode_reward_mean = 250.61
Iteration 66: episode_reward_mean = 258.13
Iteration 67: episode_reward_mean = 262.43
Iteration 68: episode_reward_mean = 269.03
Iteration 69: episode_reward_mean = 274.17
Iteration 70: episode_reward_mean = 280.93
Iteration 71: episode_reward_mean = 283.61
Iteration 72: episode_reward_mean = 290.05
Iteration 73: episode_reward_mean = 294.99
Iteration 74: episode_reward_mean = 302.37
Iteration 75: episode_reward_mean = 309.73
Iteration 76: episode_reward_mean = 317.31
Iteration 77: episode_reward_mean = 324.97
Iteration 78: episode_reward_mean = 332.86
Iteration 79: episode_reward_mean = 336.48
Iteration 80: episode_reward_mean = 344.22
Iteration 81: episode_reward_mean = 347.90
Iteration 82: episode_reward_mean = 355.98
Iteration 83: episode_reward_mean = 362.75
Iteration 84: episode_reward_mean = 370.29
Iteration 85: episode_reward_mean = 376.45
Iteration 86: episode_reward_mean = 382.10
Iteration 87: episode_reward_mean = 387.46
Iteration 88: episode_reward_mean = 394.52
Iteration 89: episode_reward_mean = 402.23
Iteration 90: episode_reward_mean = 405.47
Iteration 91: episode_reward_mean = 394.87
Iteration 92: episode_reward_mean = 396.60
Iteration 93: episode_reward_mean = 402.83
Iteration 94: episode_reward_mean = 408.18
Iteration 95: episode_reward_mean = 408.18
Iteration 96: episode_reward_mean = 399.74
Iteration 97: episode_reward_mean = 398.98
Iteration 98: episode_reward_mean = 395.53
Iteration 99: episode_reward_mean = 397.95
Iteration 100: episode_reward_mean = 397.95
Iteration 101: episode_reward_mean = 398.70
Iteration 102: episode_reward_mean = 403.49
Iteration 103: episode_reward_mean = 404.91
Iteration 104: episode_reward_mean = 408.34
Iteration 105: episode_reward_mean = 408.34
Iteration 106: episode_reward_mean = 408.34
Iteration 107: episode_reward_mean = 408.34
Iteration 108: episode_reward_mean = 408.34
Iteration 109: episode_reward_mean = 412.08
Iteration 110: episode_reward_mean = 412.08
Iteration 111: episode_reward_mean = 409.68
Iteration 112: episode_reward_mean = 410.48
Iteration 113: episode_reward_mean = 413.49
Iteration 114: episode_reward_mean = 416.19
Iteration 115: episode_reward_mean = 419.48
Iteration 116: episode_reward_mean = 419.79
Iteration 117: episode_reward_mean = 419.79
Iteration 118: episode_reward_mean = 415.82
Iteration 119: episode_reward_mean = 415.82
Iteration 120: episode_reward_mean = 414.63
Iteration 121: episode_reward_mean = 409.34
Iteration 122: episode_reward_mean = 412.54
Iteration 123: episode_reward_mean = 412.54
Iteration 124: episode_reward_mean = 412.54
Iteration 125: episode_reward_mean = 408.86
Iteration 126: episode_reward_mean = 408.86
Iteration 127: episode_reward_mean = 406.25
Iteration 128: episode_reward_mean = 406.25
Iteration 129: episode_reward_mean = 406.25
Iteration 130: episode_reward_mean = 402.52
Iteration 131: episode_reward_mean = 406.30
Iteration 132: episode_reward_mean = 413.13
Iteration 133: episode_reward_mean = 420.76
Iteration 134: episode_reward_mean = 429.05
Iteration 135: episode_reward_mean = 435.76
Iteration 136: episode_reward_mean = 435.76
Iteration 137: episode_reward_mean = 436.87
Iteration 138: episode_reward_mean = 433.31
Iteration 139: episode_reward_mean = 433.31
Iteration 140: episode_reward_mean = 439.22
Iteration 141: episode_reward_mean = 438.47
Iteration 142: episode_reward_mean = 438.84
Iteration 143: episode_reward_mean = 437.27
Iteration 144: episode_reward_mean = 433.08
Iteration 145: episode_reward_mean = 430.78
Iteration 146: episode_reward_mean = 430.78
Iteration 147: episode_reward_mean = 428.28
Iteration 148: episode_reward_mean = 428.28
Iteration 149: episode_reward_mean = 427.45
Iteration 150: episode_reward_mean = 427.45
Iteration 151: episode_reward_mean = 425.18
Iteration 152: episode_reward_mean = 423.89
Iteration 153: episode_reward_mean = 420.40
Iteration 154: episode_reward_mean = 422.80
Iteration 155: episode_reward_mean = 422.80
Iteration 156: episode_reward_mean = 422.80
Iteration 157: episode_reward_mean = 425.82
Iteration 158: episode_reward_mean = 425.82
Iteration 159: episode_reward_mean = 425.82
Iteration 160: episode_reward_mean = 425.82
Iteration 161: episode_reward_mean = 429.79
Iteration 162: episode_reward_mean = 429.79
Iteration 163: episode_reward_mean = 430.98
Iteration 164: episode_reward_mean = 431.52
Iteration 165: episode_reward_mean = 434.69
Iteration 166: episode_reward_mean = 434.69
Iteration 167: episode_reward_mean = 434.69
Iteration 168: episode_reward_mean = 434.69
Iteration 169: episode_reward_mean = 438.37
Iteration 170: episode_reward_mean = 437.09
Iteration 171: episode_reward_mean = 437.09
Iteration 172: episode_reward_mean = 437.09
Iteration 173: episode_reward_mean = 437.09
Iteration 174: episode_reward_mean = 440.82
Iteration 175: episode_reward_mean = 440.82
Iteration 176: episode_reward_mean = 442.61
Iteration 177: episode_reward_mean = 439.19
Iteration 178: episode_reward_mean = 429.24
Iteration 179: episode_reward_mean = 422.77
Iteration 180: episode_reward_mean = 412.25
Iteration 181: episode_reward_mean = 402.48
Iteration 182: episode_reward_mean = 394.14
Iteration 183: episode_reward_mean = 393.28
Iteration 184: episode_reward_mean = 387.77
Iteration 185: episode_reward_mean = 386.52
Iteration 186: episode_reward_mean = 375.51
Iteration 187: episode_reward_mean = 363.94
Iteration 188: episode_reward_mean = 348.82
Iteration 189: episode_reward_mean = 344.57
Iteration 190: episode_reward_mean = 334.43
Iteration 191: episode_reward_mean = 324.73
Iteration 192: episode_reward_mean = 316.24
Iteration 193: episode_reward_mean = 307.77
Iteration 194: episode_reward_mean = 295.34
Iteration 195: episode_reward_mean = 281.15
Iteration 196: episode_reward_mean = 261.00
Iteration 197: episode_reward_mean = 216.40
Iteration 198: episode_reward_mean = 204.33
Iteration 199: episode_reward_mean = 204.57
Iteration 200: episode_reward_mean = 206.05
Iteration 201: episode_reward_mean = 210.92
Iteration 202: episode_reward_mean = 217.82
Iteration 203: episode_reward_mean = 224.48
Iteration 204: episode_reward_mean = 231.64
Iteration 205: episode_reward_mean = 236.68
Iteration 206: episode_reward_mean = 242.40
Iteration 207: episode_reward_mean = 250.16
Iteration 208: episode_reward_mean = 257.76
Iteration 209: episode_reward_mean = 260.89
Iteration 210: episode_reward_mean = 265.72
Iteration 211: episode_reward_mean = 269.35
Iteration 212: episode_reward_mean = 268.94
Iteration 213: episode_reward_mean = 274.45
Iteration 214: episode_reward_mean = 278.51
Iteration 215: episode_reward_mean = 284.06
Iteration 216: episode_reward_mean = 287.97
Iteration 217: episode_reward_mean = 294.94
Iteration 218: episode_reward_mean = 301.63
Iteration 219: episode_reward_mean = 306.75
Iteration 220: episode_reward_mean = 309.54
Iteration 221: episode_reward_mean = 314.51
Iteration 222: episode_reward_mean = 315.91
Iteration 223: episode_reward_mean = 321.25
Iteration 224: episode_reward_mean = 325.85
Iteration 225: episode_reward_mean = 329.40
Iteration 226: episode_reward_mean = 330.33
Iteration 227: episode_reward_mean = 335.41
Iteration 228: episode_reward_mean = 340.29
Iteration 229: episode_reward_mean = 348.07
Iteration 230: episode_reward_mean = 353.46
Iteration 231: episode_reward_mean = 358.28
Iteration 232: episode_reward_mean = 362.26
Iteration 233: episode_reward_mean = 367.10
Iteration 234: episode_reward_mean = 376.65
Iteration 235: episode_reward_mean = 386.30
Iteration 236: episode_reward_mean = 390.80
Iteration 237: episode_reward_mean = 398.36
Iteration 238: episode_reward_mean = 407.73
Iteration 239: episode_reward_mean = 416.75
Iteration 240: episode_reward_mean = 426.05
Iteration 241: episode_reward_mean = 435.65
Iteration 242: episode_reward_mean = 442.13
Iteration 243: episode_reward_mean = 446.00
Iteration 244: episode_reward_mean = 455.78
Iteration 245: episode_reward_mean = 462.82
Iteration 246: episode_reward_mean = 462.82
Iteration 247: episode_reward_mean = 469.42
Iteration 248: episode_reward_mean = 469.42
Iteration 249: episode_reward_mean = 469.42
Iteration 250: episode_reward_mean = 469.42
Iteration 251: episode_reward_mean = 469.42
Iteration 252: episode_reward_mean = 469.42
Iteration 253: episode_reward_mean = 469.42
Iteration 254: episode_reward_mean = 469.42
Iteration 255: episode_reward_mean = 469.42
Iteration 256: episode_reward_mean = 469.42
Iteration 257: episode_reward_mean = 469.42
Iteration 258: episode_reward_mean = 469.42
Iteration 259: episode_reward_mean = 474.07
Iteration 260: episode_reward_mean = 474.07
Iteration 261: episode_reward_mean = 478.37
Iteration 262: episode_reward_mean = 478.37
Iteration 263: episode_reward_mean = 482.81
Iteration 264: episode_reward_mean = 482.81
Iteration 265: episode_reward_mean = 486.16
Iteration 266: episode_reward_mean = 486.16
Iteration 267: episode_reward_mean = 486.16
Iteration 268: episode_reward_mean = 486.16
Iteration 269: episode_reward_mean = 481.42
Iteration 270: episode_reward_mean = 481.42
Iteration 271: episode_reward_mean = 485.19
Iteration 272: episode_reward_mean = 487.79
Iteration 273: episode_reward_mean = 487.79
Iteration 274: episode_reward_mean = 489.06
Iteration 275: episode_reward_mean = 494.99
Iteration 276: episode_reward_mean = 494.99
Iteration 277: episode_reward_mean = 494.99
Iteration 278: episode_reward_mean = 494.99
Iteration 279: episode_reward_mean = 494.99
Iteration 280: episode_reward_mean = 494.99
Iteration 281: episode_reward_mean = 494.99
Iteration 282: episode_reward_mean = 494.99
Iteration 283: episode_reward_mean = 494.99
Iteration 284: episode_reward_mean = 494.99
Iteration 285: episode_reward_mean = 494.99
Iteration 286: episode_reward_mean = 494.99
Iteration 287: episode_reward_mean = 494.99
Iteration 288: episode_reward_mean = 494.99
Iteration 289: episode_reward_mean = 494.99
Iteration 290: episode_reward_mean = 494.99
Iteration 291: episode_reward_mean = 495.26
Iteration 292: episode_reward_mean = 495.26
Iteration 293: episode_reward_mean = 482.59
Iteration 294: episode_reward_mean = 478.73
Iteration 295: episode_reward_mean = 477.72
Iteration 296: episode_reward_mean = 473.17
Iteration 297: episode_reward_mean = 466.78
Iteration 298: episode_reward_mean = 454.03
Iteration 299: episode_reward_mean = 449.37
Iteration 300: episode_reward_mean = 437.69

Checkpoint saved at: /Users/ali/ray_results/DQN_RandomizedCartPole-v1_2025-07-07_13-20-258b5eadpn/checkpoint_000300

Training Complete
Avg Training CPU Usage: 32.56%
Peak Memory Usage: 640.47 MB
Final Memory Change: 91.20 MB
Training Time: 701.10 seconds

Running trained DQN policy on RandomizedCartPole-v1 and logging state evolution...

2025-07-07 13:32:06,327	WARNING util.py:66 -- Install gputil for GPU system monitoring.
2025-07-07 13:32:06,362	INFO trainable.py:766 -- Restored on 127.0.0.1 from checkpoint: /Users/ali/ray_results/DQN_RandomizedCartPole-v1_2025-07-07_13-20-258b5eadpn/checkpoint_000300
2025-07-07 13:32:06,362	INFO trainable.py:775 -- Current state after restoring: {'_iteration': 300, '_timesteps_total': None, '_time_total': 696.3167073726654, '_episodes_total': 1153}
Inference log saved to cartpole_inference_DQN_log.csv


